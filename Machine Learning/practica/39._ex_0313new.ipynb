{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Exercise #0313"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bagging ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install once.\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "warnings.filterwarnings(action='ignore')                  # Turn off the warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Read in data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data.\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanatory variables.\n",
    "X = data['data']\n",
    "variable_names = data['feature_names']\n",
    "print(variable_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response variable.\n",
    "# Relabel such that 0 = 'benign' and 1 = malignant.\n",
    "Y = 1 - data['target']\n",
    "label = list(data['target_names'])\n",
    "label.reverse()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Train a Random Forest with 100 estimators, max_depth=5, min_samples_leaf=2 and random_state=123. Then fit and predict.\n",
    "# (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "RFC = ??\n",
    "RFC.??\n",
    "Y_pred = ??\n",
    "print( \"Random Forest accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most important variables.\n",
    "variable_importance = pd.Series(RFC.feature_importances_, index = variable_names)\n",
    "top_variables_10 = variable_importance.sort_values(ascending=False)[:10]\n",
    "sns.barplot(x=top_variables_10.values, y = top_variables_10.index, ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Boosting Ensemble:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.  AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Train an AdaBoost with a Decision Tree (max_deph = 10) as base estimator, 100 estimators, learning_rate=0.01 and random_state=123 \n",
    "# (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). Then fit and predict.\n",
    "ABC = ??\n",
    "ABC.??\n",
    "Y_pred = ??\n",
    "print( \"AdaBoost accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most important variables.\n",
    "variable_importance = pd.Series(ABC.feature_importances_, index = variable_names)\n",
    "top_variables_10 = variable_importance.sort_values(ascending=False)[:10]\n",
    "sns.barplot(x=top_variables_10.values, y = top_variables_10.index, ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.  Gradient Boosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification by Gradient Boosting with  100 estimators, learning_rate=0.01, min_samples_leaf=2, max_leaf_nodes=30, and random_state=123 \n",
    "# (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html). Then fit and predict.\n",
    "GBC = ??\n",
    "GBC.??\n",
    "Y_pred = ??\n",
    "print( \"Gradient Boosting accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most important variables.\n",
    "variable_importance = pd.Series(GBC.feature_importances_, index = variable_names)\n",
    "top_variables_10 = variable_importance.sort_values(ascending=False)[:10]\n",
    "sns.barplot(x=top_variables_10.values, y = top_variables_10.index, ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification by XGBoost.\n",
    "# Classification by XGBoost with 500 estimators, learning_rate=0.1, max_depth = 4, and random_state=123 \n",
    "# (https://xgboost.readthedocs.io/en/stable/python/python_api.html). Then fit and predict.\n",
    "XGBC = ??\n",
    "XGBC.??\n",
    "Y_pred = ??\n",
    "print( \"XGBoost accuracy : \" + str(np.round(metrics.accuracy_score(Y_test,Y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the top 10 most important variables.\n",
    "variable_importance = pd.Series(XGBC.feature_importances_, index = variable_names)\n",
    "top_variables_10 = variable_importance.sort_values(ascending=False)[:10]\n",
    "sns.barplot(x=top_variables_10.values, y = top_variables_10.index, ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The hyperparameters of XGBClassifier can be optimized using GridSearchCV() and RandomSearchCV(). Students are encouraged to explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
