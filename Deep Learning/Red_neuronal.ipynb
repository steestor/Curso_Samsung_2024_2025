{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab9253b-5006-4058-ad9b-0ba74b71eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED NEURONAL MODELO DE REGRESIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd5567bb-d7d9-4f48-9496-c75c1204f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as pyplot\n",
    "# Utilizaremos keras para crear la red neuronal\n",
    "import keras\n",
    "from keras.models import Sequential # Puede ser secuencial y \n",
    "from keras.layers import Dense\n",
    "from sklearn .model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4640a230-3c57-47d0-a9ea-4f524eee3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.5488135 ]\n",
      "  [0.67781654]]\n",
      "\n",
      " [[0.71518937]\n",
      "  [0.27000797]]\n",
      "\n",
      " [[0.60276338]\n",
      "  [0.73519402]]\n",
      "\n",
      " [[0.54488318]\n",
      "  [0.96218855]]\n",
      "\n",
      " [[0.4236548 ]\n",
      "  [0.24875314]]\n",
      "\n",
      " [[0.64589411]\n",
      "  [0.57615733]]\n",
      "\n",
      " [[0.43758721]\n",
      "  [0.59204193]]\n",
      "\n",
      " [[0.891773  ]\n",
      "  [0.57225191]]\n",
      "\n",
      " [[0.96366276]\n",
      "  [0.22308163]]\n",
      "\n",
      " [[0.38344152]\n",
      "  [0.95274901]]\n",
      "\n",
      " [[0.79172504]\n",
      "  [0.44712538]]\n",
      "\n",
      " [[0.52889492]\n",
      "  [0.84640867]]\n",
      "\n",
      " [[0.56804456]\n",
      "  [0.69947928]]\n",
      "\n",
      " [[0.92559664]\n",
      "  [0.29743695]]\n",
      "\n",
      " [[0.07103606]\n",
      "  [0.81379782]]\n",
      "\n",
      " [[0.0871293 ]\n",
      "  [0.39650574]]\n",
      "\n",
      " [[0.0202184 ]\n",
      "  [0.8811032 ]]\n",
      "\n",
      " [[0.83261985]\n",
      "  [0.58127287]]\n",
      "\n",
      " [[0.77815675]\n",
      "  [0.88173536]]\n",
      "\n",
      " [[0.87001215]\n",
      "  [0.69253159]]\n",
      "\n",
      " [[0.97861834]\n",
      "  [0.72525428]]\n",
      "\n",
      " [[0.79915856]\n",
      "  [0.50132438]]\n",
      "\n",
      " [[0.46147936]\n",
      "  [0.95608363]]\n",
      "\n",
      " [[0.78052918]\n",
      "  [0.6439902 ]]\n",
      "\n",
      " [[0.11827443]\n",
      "  [0.42385505]]\n",
      "\n",
      " [[0.63992102]\n",
      "  [0.60639321]]\n",
      "\n",
      " [[0.14335329]\n",
      "  [0.0191932 ]]\n",
      "\n",
      " [[0.94466892]\n",
      "  [0.30157482]]\n",
      "\n",
      " [[0.52184832]\n",
      "  [0.66017354]]\n",
      "\n",
      " [[0.41466194]\n",
      "  [0.29007761]]\n",
      "\n",
      " [[0.26455561]\n",
      "  [0.61801543]]\n",
      "\n",
      " [[0.77423369]\n",
      "  [0.4287687 ]]\n",
      "\n",
      " [[0.45615033]\n",
      "  [0.13547406]]\n",
      "\n",
      " [[0.56843395]\n",
      "  [0.29828233]]\n",
      "\n",
      " [[0.0187898 ]\n",
      "  [0.56996491]]\n",
      "\n",
      " [[0.6176355 ]\n",
      "  [0.59087276]]\n",
      "\n",
      " [[0.61209572]\n",
      "  [0.57432525]]\n",
      "\n",
      " [[0.616934  ]\n",
      "  [0.65320082]]\n",
      "\n",
      " [[0.94374808]\n",
      "  [0.65210327]]\n",
      "\n",
      " [[0.6818203 ]\n",
      "  [0.43141844]]\n",
      "\n",
      " [[0.3595079 ]\n",
      "  [0.8965466 ]]\n",
      "\n",
      " [[0.43703195]\n",
      "  [0.36756187]]\n",
      "\n",
      " [[0.6976312 ]\n",
      "  [0.43586493]]\n",
      "\n",
      " [[0.06022547]\n",
      "  [0.89192336]]\n",
      "\n",
      " [[0.66676672]\n",
      "  [0.80619399]]\n",
      "\n",
      " [[0.67063787]\n",
      "  [0.70388858]]\n",
      "\n",
      " [[0.21038256]\n",
      "  [0.10022689]]\n",
      "\n",
      " [[0.1289263 ]\n",
      "  [0.91948261]]\n",
      "\n",
      " [[0.31542835]\n",
      "  [0.7142413 ]]\n",
      "\n",
      " [[0.36371077]\n",
      "  [0.99884701]]\n",
      "\n",
      " [[0.57019677]\n",
      "  [0.1494483 ]]\n",
      "\n",
      " [[0.43860151]\n",
      "  [0.86812606]]\n",
      "\n",
      " [[0.98837384]\n",
      "  [0.16249293]]\n",
      "\n",
      " [[0.10204481]\n",
      "  [0.61555956]]\n",
      "\n",
      " [[0.20887676]\n",
      "  [0.12381998]]\n",
      "\n",
      " [[0.16130952]\n",
      "  [0.84800823]]\n",
      "\n",
      " [[0.65310833]\n",
      "  [0.80731896]]\n",
      "\n",
      " [[0.2532916 ]\n",
      "  [0.56910074]]\n",
      "\n",
      " [[0.46631077]\n",
      "  [0.4071833 ]]\n",
      "\n",
      " [[0.24442559]\n",
      "  [0.069167  ]]\n",
      "\n",
      " [[0.15896958]\n",
      "  [0.69742877]]\n",
      "\n",
      " [[0.11037514]\n",
      "  [0.45354268]]\n",
      "\n",
      " [[0.65632959]\n",
      "  [0.7220556 ]]\n",
      "\n",
      " [[0.13818295]\n",
      "  [0.86638233]]\n",
      "\n",
      " [[0.19658236]\n",
      "  [0.97552151]]\n",
      "\n",
      " [[0.36872517]\n",
      "  [0.85580334]]\n",
      "\n",
      " [[0.82099323]\n",
      "  [0.01171408]]\n",
      "\n",
      " [[0.09710128]\n",
      "  [0.35997806]]\n",
      "\n",
      " [[0.83794491]\n",
      "  [0.72999056]]\n",
      "\n",
      " [[0.09609841]\n",
      "  [0.17162968]]\n",
      "\n",
      " [[0.97645947]\n",
      "  [0.52103661]]\n",
      "\n",
      " [[0.4686512 ]\n",
      "  [0.05433799]]\n",
      "\n",
      " [[0.97676109]\n",
      "  [0.19999652]]\n",
      "\n",
      " [[0.60484552]\n",
      "  [0.01852179]]\n",
      "\n",
      " [[0.73926358]\n",
      "  [0.7936977 ]]\n",
      "\n",
      " [[0.03918779]\n",
      "  [0.22392469]]\n",
      "\n",
      " [[0.28280696]\n",
      "  [0.34535168]]\n",
      "\n",
      " [[0.12019656]\n",
      "  [0.92808129]]\n",
      "\n",
      " [[0.2961402 ]\n",
      "  [0.7044144 ]]\n",
      "\n",
      " [[0.11872772]\n",
      "  [0.03183893]]\n",
      "\n",
      " [[0.31798318]\n",
      "  [0.16469416]]\n",
      "\n",
      " [[0.41426299]\n",
      "  [0.6214784 ]]\n",
      "\n",
      " [[0.0641475 ]\n",
      "  [0.57722859]]\n",
      "\n",
      " [[0.69247212]\n",
      "  [0.23789282]]\n",
      "\n",
      " [[0.56660145]\n",
      "  [0.934214  ]]\n",
      "\n",
      " [[0.26538949]\n",
      "  [0.61396596]]\n",
      "\n",
      " [[0.52324805]\n",
      "  [0.5356328 ]]\n",
      "\n",
      " [[0.09394051]\n",
      "  [0.58990998]]\n",
      "\n",
      " [[0.5759465 ]\n",
      "  [0.73012203]]\n",
      "\n",
      " [[0.9292962 ]\n",
      "  [0.311945  ]]\n",
      "\n",
      " [[0.31856895]\n",
      "  [0.39822106]]\n",
      "\n",
      " [[0.66741038]\n",
      "  [0.20984375]]\n",
      "\n",
      " [[0.13179786]\n",
      "  [0.18619301]]\n",
      "\n",
      " [[0.7163272 ]\n",
      "  [0.94437239]]\n",
      "\n",
      " [[0.28940609]\n",
      "  [0.7395508 ]]\n",
      "\n",
      " [[0.18319136]\n",
      "  [0.49045881]]\n",
      "\n",
      " [[0.58651293]\n",
      "  [0.22741463]]\n",
      "\n",
      " [[0.02010755]\n",
      "  [0.25435648]]\n",
      "\n",
      " [[0.82894003]\n",
      "  [0.05802916]]\n",
      "\n",
      " [[0.00469548]\n",
      "  [0.43441663]]], shape=(100, 2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Creación de la ecuación\n",
    "\n",
    "# Creamos valores aleatorios de una sola dimension\n",
    "np.random.seed(0)\n",
    "X1 = np.random.rand(100,1)\n",
    "X2 = np.random.rand(100,1)\n",
    "\n",
    "# la parte de np.random es ruido\n",
    "y = 3*X1 + X2 + np.random.rand(100, 1)*0.1\n",
    "\n",
    "X= tf.stack((X1,X2), axis=1)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3edb4f1e-fffa-4d2d-b7f4-c2a87764863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,))) # Definimos la capa de salida, tenemos 1 red neuronal, input_shape\n",
    "\n",
    "# ya tenemos la red neuronal, ahora la vamos a compilar\n",
    "model.compile(optimizer=\"sgd\", loss=\"mse\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58026c9-c3d9-483c-80cc-7108296cab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Porque 3 parametros? 2 parametros de entrada + 1 de bias o termino independiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8886517d-e512-4ad9-974f-871c05741d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 4.7044 \n",
      "Epoch 2/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.7734\n",
      "Epoch 3/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6479\n",
      "Epoch 4/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1419\n",
      "Epoch 5/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1287\n",
      "Epoch 6/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7313 \n",
      "Epoch 7/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7652\n",
      "Epoch 8/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6148 \n",
      "Epoch 9/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6692 \n",
      "Epoch 10/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6316\n",
      "Epoch 11/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5648\n",
      "Epoch 12/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5889\n",
      "Epoch 13/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6241\n",
      "Epoch 14/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5238\n",
      "Epoch 15/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4851\n",
      "Epoch 16/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4567\n",
      "Epoch 17/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5037\n",
      "Epoch 18/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4033\n",
      "Epoch 19/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4361\n",
      "Epoch 20/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4335 \n",
      "Epoch 21/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3922\n",
      "Epoch 22/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3638\n",
      "Epoch 23/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4702\n",
      "Epoch 24/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4083\n",
      "Epoch 25/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3764 \n",
      "Epoch 26/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3803 \n",
      "Epoch 27/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.35346\n",
      "Epoch 28/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3566\n",
      "Epoch 29/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3023\n",
      "Epoch 30/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3255 \n",
      "Epoch 31/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3460 \n",
      "Epoch 32/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2888\n",
      "Epoch 33/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3006\n",
      "Epoch 34/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2712\n",
      "Epoch 35/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3358 \n",
      "Epoch 36/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.28186\n",
      "Epoch 37/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2717\n",
      "Epoch 38/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2794\n",
      "Epoch 39/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2625\n",
      "Epoch 40/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2329\n",
      "Epoch 41/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2538 \n",
      "Epoch 42/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2301\n",
      "Epoch 43/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2293\n",
      "Epoch 44/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2339\n",
      "Epoch 45/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2327\n",
      "Epoch 46/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1960\n",
      "Epoch 47/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1933\n",
      "Epoch 48/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1814\n",
      "Epoch 49/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2015\n",
      "Epoch 50/50\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1870 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fb5a760510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe369458-3ab7-4ee0-8983-b651678573dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "[[-0.05662826]\n",
      " [-0.31092507]\n",
      " [-0.1136101 ]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([[0.2,0.1], [0.5,0.4], [0.8,0.3]]) # Nuevos datos para probar\n",
    "predicciones = model.predict(X_test)\n",
    "print(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882d1da-6a13-4cb3-96b9-f89b9b00ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED NEURONAL REGRESIÓN LOGÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d402f22f-671e-49d4-9ea6-25c404deaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X= np.random.rand(100,2)\n",
    "y=np.random.randint(2, size=(100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4910e56b-7673-4162-84f2-0c0acb2d38a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c118efe7-4175-4c9a-a603-66d11af13210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "[[0.4737713 ]\n",
      " [0.44075072]\n",
      " [0.39261836]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([[0.2,0.1], [0.5,0.4], [0.8,0.3]]) # Nuevos datos para probar\n",
    "predicciones = model.predict(X_test)\n",
    "print(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "08ecaef6-c231-4fc3-bcbb-e68350f3a1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.0'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f05695-a608-4a91-bfdb-bfddf185f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICCION DEL PRECIO DE LAS CASAS DE BOSTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ebd6a05-56c8-4f3e-969a-bf43cfe4b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"./data_boston.csv\", header=\"infer\", sep=\";\")\n",
    "X= df.drop(columns=['price'])\n",
    "y= df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c8593fe-94a8-4db4-aa55-d6310fc7d0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio   black  lstat\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3  396.90   4.98\n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8  396.90   9.14\n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8  392.83   4.03\n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7  394.63   2.94\n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7  396.90   5.33"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d449aa7-9b98-4cc1-a5d6-63927ea75a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24.0\n",
       "1    21.6\n",
       "2    34.7\n",
       "3    33.4\n",
       "4    36.2\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541ea20-a118-46f5-9129-35e4a7c45f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a las redes neuronales les gustan los datos normalizados o escalados. para eso utilizaremos el minmaxScal. Pero solo escalaremos los valores de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c007a39-bfa1-4f0e-bcc7-1200d3295e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0bf83b17-d98b-4791-9a06-78169184cabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "# Tendremos 13 variables de entrada\n",
    "n_vars = X_train.shape[-1]\n",
    "n_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f145c377-8108-48e0-bbf9-3d16e30bb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Sequential()\n",
    "modelo.add(Dense(1, input_shape=(n_vars,), activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b26af29-689b-49f6-8945-bb56b40d245b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m14\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> (56.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14\u001b[0m (56.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14</span> (56.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14\u001b[0m (56.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelo.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"mse\"])\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93132913-3fa8-4bbf-a146-2acb01cf0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 22.1003 - mse: 566.9464 - val_loss: 22.0834 - val_mse: 556.2103\n",
      "Epoch 2/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.4588 - mse: 607.2072 - val_loss: 21.9138 - val_mse: 548.9415\n",
      "Epoch 3/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.1886 - mse: 597.6982 - val_loss: 21.7447 - val_mse: 541.7460\n",
      "Epoch 4/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.7386 - mse: 558.4028 - val_loss: 21.5771 - val_mse: 534.6714\n",
      "Epoch 5/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.3085 - mse: 526.4029 - val_loss: 21.4090 - val_mse: 527.6329\n",
      "Epoch 6/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 22.0972 - mse: 587.5599 - val_loss: 21.2394 - val_mse: 520.6002\n",
      "Epoch 7/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.6999 - mse: 567.5862 - val_loss: 21.0700 - val_mse: 513.6297\n",
      "Epoch 8/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 21.1654 - mse: 529.2579 - val_loss: 20.9007 - val_mse: 506.7281\n",
      "Epoch 9/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.8621 - mse: 523.9290 - val_loss: 20.7324 - val_mse: 499.9241\n",
      "Epoch 10/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.4724 - mse: 554.5577 - val_loss: 20.5632 - val_mse: 493.1475\n",
      "Epoch 11/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 21.2111 - mse: 533.3811 - val_loss: 20.3940 - val_mse: 486.4286\n",
      "Epoch 12/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.2922 - mse: 514.3299 - val_loss: 20.2255 - val_mse: 479.7949\n",
      "Epoch 13/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.7828 - mse: 527.7864 - val_loss: 20.0574 - val_mse: 473.2337\n",
      "Epoch 14/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 20.6971 - mse: 519.8440 - val_loss: 19.8880 - val_mse: 466.6817\n",
      "Epoch 15/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 20.6699 - mse: 532.0557 - val_loss: 19.7185 - val_mse: 460.1883\n",
      "Epoch 16/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.4391 - mse: 478.2567 - val_loss: 19.5496 - val_mse: 453.7831\n",
      "Epoch 17/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.2441 - mse: 523.5095 - val_loss: 19.3807 - val_mse: 447.4303\n",
      "Epoch 18/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.6717 - mse: 488.1989 - val_loss: 19.2124 - val_mse: 441.1602\n",
      "Epoch 19/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.6302 - mse: 485.5063 - val_loss: 19.0450 - val_mse: 434.9772\n",
      "Epoch 20/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.1939 - mse: 475.0098 - val_loss: 18.8780 - val_mse: 428.8699\n",
      "Epoch 21/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.6459 - mse: 490.0236 - val_loss: 18.7111 - val_mse: 422.8185\n",
      "Epoch 22/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.3120 - mse: 420.2436 - val_loss: 18.5451 - val_mse: 416.8518\n",
      "Epoch 23/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.4396 - mse: 420.1030 - val_loss: 18.3791 - val_mse: 410.9460\n",
      "Epoch 24/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.0378 - mse: 463.8486 - val_loss: 18.2132 - val_mse: 405.1053\n",
      "Epoch 25/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.1669 - mse: 424.5515 - val_loss: 18.0453 - val_mse: 399.2589\n",
      "Epoch 26/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 18.7146 - mse: 448.2194 - val_loss: 17.8796 - val_mse: 393.5405\n",
      "Epoch 27/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.0238 - mse: 475.1806 - val_loss: 17.7129 - val_mse: 387.8443\n",
      "Epoch 28/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.9732 - mse: 425.3795 - val_loss: 17.5462 - val_mse: 382.2133\n",
      "Epoch 29/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.8564 - mse: 377.8066 - val_loss: 17.3856 - val_mse: 376.7776\n",
      "Epoch 30/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.1092 - mse: 395.5522 - val_loss: 17.2275 - val_mse: 371.3245\n",
      "Epoch 31/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.0791 - mse: 396.8099 - val_loss: 17.0754 - val_mse: 365.9050\n",
      "Epoch 32/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.3802 - mse: 393.7677 - val_loss: 16.9250 - val_mse: 360.6029\n",
      "Epoch 33/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.7210 - mse: 413.5220 - val_loss: 16.7772 - val_mse: 355.4425\n",
      "Epoch 34/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.0278 - mse: 336.2000 - val_loss: 16.6251 - val_mse: 350.2049\n",
      "Epoch 35/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.7714 - mse: 386.5342 - val_loss: 16.4774 - val_mse: 345.1581\n",
      "Epoch 36/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 16.2312 - mse: 363.0686 - val_loss: 16.3299 - val_mse: 340.1704\n",
      "Epoch 37/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.6801 - mse: 367.4211 - val_loss: 16.1841 - val_mse: 335.2883\n",
      "Epoch 38/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.8456 - mse: 341.3802 - val_loss: 16.0420 - val_mse: 330.5786\n",
      "Epoch 39/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.0133 - mse: 346.9575 - val_loss: 15.8967 - val_mse: 325.8147\n",
      "Epoch 40/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.4725 - mse: 322.9836 - val_loss: 15.7572 - val_mse: 321.2811\n",
      "Epoch 41/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.6072 - mse: 388.5002 - val_loss: 15.6159 - val_mse: 316.7390\n",
      "Epoch 42/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.5583 - mse: 363.0813 - val_loss: 15.4766 - val_mse: 312.3086\n",
      "Epoch 43/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.2806 - mse: 366.0707 - val_loss: 15.3339 - val_mse: 307.8222\n",
      "Epoch 44/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.4640 - mse: 331.8148 - val_loss: 15.1959 - val_mse: 303.5211\n",
      "Epoch 45/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.3022 - mse: 375.7098 - val_loss: 15.0599 - val_mse: 299.3304\n",
      "Epoch 46/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.6905 - mse: 313.2728 - val_loss: 14.9229 - val_mse: 295.1579\n",
      "Epoch 47/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.8705 - mse: 315.5225 - val_loss: 14.7879 - val_mse: 291.0808\n",
      "Epoch 48/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.7705 - mse: 310.2025 - val_loss: 14.6467 - val_mse: 286.8698\n",
      "Epoch 49/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.9082 - mse: 315.9219 - val_loss: 14.5140 - val_mse: 282.9425\n",
      "Epoch 50/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.9524 - mse: 318.5785 - val_loss: 14.3787 - val_mse: 278.9890\n",
      "Epoch 51/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.8660 - mse: 279.7422 - val_loss: 14.2427 - val_mse: 275.0692\n",
      "Epoch 52/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.8664 - mse: 324.5215 - val_loss: 14.1062 - val_mse: 271.1765\n",
      "Epoch 53/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.8214 - mse: 289.1212 - val_loss: 13.9751 - val_mse: 267.4700\n",
      "Epoch 54/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.2846 - mse: 299.7414 - val_loss: 13.8397 - val_mse: 263.6824\n",
      "Epoch 55/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 14.6056 - mse: 315.1392 - val_loss: 13.7110 - val_mse: 260.0784\n",
      "Epoch 56/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.5442 - mse: 276.2111 - val_loss: 13.5868 - val_mse: 256.5510\n",
      "Epoch 57/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.1410 - mse: 305.1249 - val_loss: 13.4655 - val_mse: 253.1321\n",
      "Epoch 58/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.5393 - mse: 282.5037 - val_loss: 13.3460 - val_mse: 249.8107\n",
      "Epoch 59/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.5773 - mse: 278.6416 - val_loss: 13.2322 - val_mse: 246.6707\n",
      "Epoch 60/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.4396 - mse: 266.3601 - val_loss: 13.1188 - val_mse: 243.5738\n",
      "Epoch 61/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.9083 - mse: 288.2235 - val_loss: 13.0003 - val_mse: 240.3783\n",
      "Epoch 62/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.0955 - mse: 254.7184 - val_loss: 12.8791 - val_mse: 237.1467\n",
      "Epoch 63/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.0462 - mse: 303.3143 - val_loss: 12.7618 - val_mse: 234.0520\n",
      "Epoch 64/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.5613 - mse: 280.0768 - val_loss: 12.6577 - val_mse: 231.2245\n",
      "Epoch 65/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.3769 - mse: 273.7434 - val_loss: 12.5467 - val_mse: 228.2455\n",
      "Epoch 66/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.5781 - mse: 275.2761 - val_loss: 12.4360 - val_mse: 225.3101\n",
      "Epoch 67/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.0893 - mse: 221.8410 - val_loss: 12.3255 - val_mse: 222.4148\n",
      "Epoch 68/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.0160 - mse: 297.6898 - val_loss: 12.2148 - val_mse: 219.5393\n",
      "Epoch 69/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.0145 - mse: 261.8918 - val_loss: 12.1097 - val_mse: 216.8393\n",
      "Epoch 70/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.7554 - mse: 257.2977 - val_loss: 12.0051 - val_mse: 214.1640\n",
      "Epoch 71/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.1345 - mse: 264.4869 - val_loss: 11.9043 - val_mse: 211.5222\n",
      "Epoch 72/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3852 - mse: 246.0020 - val_loss: 11.8091 - val_mse: 209.0494\n",
      "Epoch 73/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.9476 - mse: 256.7641 - val_loss: 11.7091 - val_mse: 206.4411\n",
      "Epoch 74/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.1447 - mse: 265.7480 - val_loss: 11.6174 - val_mse: 203.9285\n",
      "Epoch 75/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2051 - mse: 226.5755 - val_loss: 11.5270 - val_mse: 201.4581\n",
      "Epoch 76/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2302 - mse: 226.3283 - val_loss: 11.4398 - val_mse: 199.0954\n",
      "Epoch 77/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5063 - mse: 240.9241 - val_loss: 11.3548 - val_mse: 196.8178\n",
      "Epoch 78/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.5618 - mse: 248.0653 - val_loss: 11.2718 - val_mse: 194.6200\n",
      "Epoch 79/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4187 - mse: 238.7860 - val_loss: 11.1821 - val_mse: 192.2750\n",
      "Epoch 80/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4192 - mse: 239.2773 - val_loss: 11.0922 - val_mse: 189.9465\n",
      "Epoch 81/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4145 - mse: 214.2532 - val_loss: 11.0081 - val_mse: 187.7938\n",
      "Epoch 82/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7634 - mse: 214.0288 - val_loss: 10.9190 - val_mse: 185.5423\n",
      "Epoch 83/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.4615 - mse: 242.1820 - val_loss: 10.8311 - val_mse: 183.3475\n",
      "Epoch 84/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7967 - mse: 222.1170 - val_loss: 10.7466 - val_mse: 181.2549\n",
      "Epoch 85/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.3917 - mse: 240.3037 - val_loss: 10.6568 - val_mse: 179.0477\n",
      "Epoch 86/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.1324 - mse: 233.3517 - val_loss: 10.5765 - val_mse: 177.0351\n",
      "Epoch 87/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.9959 - mse: 229.7322 - val_loss: 10.4970 - val_mse: 175.0612\n",
      "Epoch 88/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.4181 - mse: 203.7819 - val_loss: 10.4127 - val_mse: 172.9997\n",
      "Epoch 89/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.9132 - mse: 228.7187 - val_loss: 10.3424 - val_mse: 171.2828\n",
      "Epoch 90/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.5559 - mse: 208.6373 - val_loss: 10.2586 - val_mse: 169.2795\n",
      "Epoch 91/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.1048 - mse: 194.1852 - val_loss: 10.1857 - val_mse: 167.5005\n",
      "Epoch 92/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.2175 - mse: 202.3639 - val_loss: 10.1081 - val_mse: 165.5221\n",
      "Epoch 93/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3007 - mse: 167.2451 - val_loss: 10.0372 - val_mse: 163.6911\n",
      "Epoch 94/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.2258 - mse: 199.0304 - val_loss: 9.9675 - val_mse: 161.8796\n",
      "Epoch 95/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.2977 - mse: 192.2914 - val_loss: 9.8970 - val_mse: 160.0795\n",
      "Epoch 96/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.6094 - mse: 173.0575 - val_loss: 9.8320 - val_mse: 158.4401\n",
      "Epoch 97/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.9226 - mse: 225.4604 - val_loss: 9.7678 - val_mse: 156.8327\n",
      "Epoch 98/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8357 - mse: 183.6506 - val_loss: 9.7026 - val_mse: 155.2279\n",
      "Epoch 99/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.4380 - mse: 241.0966 - val_loss: 9.6298 - val_mse: 153.4558\n",
      "Epoch 100/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.8538 - mse: 190.2051 - val_loss: 9.5623 - val_mse: 151.8363\n",
      "Epoch 101/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5577 - mse: 185.7028 - val_loss: 9.4937 - val_mse: 150.2101\n",
      "Epoch 102/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1148 - mse: 174.4315 - val_loss: 9.4252 - val_mse: 148.6043\n",
      "Epoch 103/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.0223 - mse: 193.2162 - val_loss: 9.3590 - val_mse: 147.0701\n",
      "Epoch 104/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.8707 - mse: 188.6299 - val_loss: 9.2900 - val_mse: 145.4440\n",
      "Epoch 105/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.0239 - mse: 193.6814 - val_loss: 9.2341 - val_mse: 144.1052\n",
      "Epoch 106/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.0429 - mse: 173.7752 - val_loss: 9.1750 - val_mse: 142.6704\n",
      "Epoch 107/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.2182 - mse: 166.2323 - val_loss: 9.1201 - val_mse: 141.3526\n",
      "Epoch 108/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1215 - mse: 162.2620 - val_loss: 9.0683 - val_mse: 140.1190\n",
      "Epoch 109/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.5317 - mse: 181.4627 - val_loss: 9.0122 - val_mse: 138.7298\n",
      "Epoch 110/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1056 - mse: 158.2981 - val_loss: 8.9654 - val_mse: 137.5443\n",
      "Epoch 111/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.3045 - mse: 165.1808 - val_loss: 8.9139 - val_mse: 136.2464\n",
      "Epoch 112/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.3185 - mse: 177.9151 - val_loss: 8.8630 - val_mse: 134.9789\n",
      "Epoch 113/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.1745 - mse: 164.7498 - val_loss: 8.8139 - val_mse: 133.7771\n",
      "Epoch 114/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6939 - mse: 154.4209 - val_loss: 8.7679 - val_mse: 132.6405\n",
      "Epoch 115/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.3299 - mse: 210.4408 - val_loss: 8.7189 - val_mse: 131.3392\n",
      "Epoch 116/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10.1995 - mse: 172.8953 - val_loss: 8.6731 - val_mse: 130.1276\n",
      "Epoch 117/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 10.2677 - mse: 165.1043 - val_loss: 8.6280 - val_mse: 128.9616\n",
      "Epoch 118/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3023 - mse: 169.3074 - val_loss: 8.5855 - val_mse: 127.8803\n",
      "Epoch 119/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.5841 - mse: 187.6163 - val_loss: 8.5457 - val_mse: 126.8928\n",
      "Epoch 120/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6274 - mse: 158.4057 - val_loss: 8.5054 - val_mse: 125.9000\n",
      "Epoch 121/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3853 - mse: 173.7447 - val_loss: 8.4660 - val_mse: 124.9406\n",
      "Epoch 122/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1939 - mse: 142.7998 - val_loss: 8.4268 - val_mse: 123.9958\n",
      "Epoch 123/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.4223 - mse: 142.6577 - val_loss: 8.3814 - val_mse: 122.8927\n",
      "Epoch 124/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8086 - mse: 162.8945 - val_loss: 8.3408 - val_mse: 121.9349\n",
      "Epoch 125/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.5279 - mse: 153.1822 - val_loss: 8.2999 - val_mse: 120.9818\n",
      "Epoch 126/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 10.3628 - mse: 168.8501 - val_loss: 8.2596 - val_mse: 120.0540\n",
      "Epoch 127/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.9533 - mse: 133.6415 - val_loss: 8.2186 - val_mse: 119.1151\n",
      "Epoch 128/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2261 - mse: 138.3916 - val_loss: 8.1807 - val_mse: 118.2660\n",
      "Epoch 129/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.6921 - mse: 152.3856 - val_loss: 8.1425 - val_mse: 117.3541\n",
      "Epoch 130/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1899 - mse: 146.7549 - val_loss: 8.1088 - val_mse: 116.5669\n",
      "Epoch 131/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.7899 - mse: 160.4009 - val_loss: 8.0691 - val_mse: 115.6328\n",
      "Epoch 132/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.5504 - mse: 148.6280 - val_loss: 8.0296 - val_mse: 114.7197\n",
      "Epoch 133/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3532 - mse: 145.2674 - val_loss: 7.9879 - val_mse: 113.7324\n",
      "Epoch 134/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.6289 - mse: 126.3950 - val_loss: 7.9556 - val_mse: 112.9699\n",
      "Epoch 135/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0060 - mse: 132.2818 - val_loss: 7.9212 - val_mse: 112.1625\n",
      "Epoch 136/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.7778 - mse: 158.1679 - val_loss: 7.8843 - val_mse: 111.2986\n",
      "Epoch 137/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9717 - mse: 135.7801 - val_loss: 7.8500 - val_mse: 110.5064\n",
      "Epoch 138/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.9537 - mse: 130.0284 - val_loss: 7.8169 - val_mse: 109.7094\n",
      "Epoch 139/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8595 - mse: 132.6770 - val_loss: 7.7867 - val_mse: 108.9970\n",
      "Epoch 140/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.6864 - mse: 150.4421 - val_loss: 7.7510 - val_mse: 108.1505\n",
      "Epoch 141/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.2112 - mse: 135.3726 - val_loss: 7.7202 - val_mse: 107.4424\n",
      "Epoch 142/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.5584 - mse: 129.7284 - val_loss: 7.6890 - val_mse: 106.7304\n",
      "Epoch 143/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 9.6746 - mse: 154.0219 - val_loss: 7.6542 - val_mse: 105.9352\n",
      "Epoch 144/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.1856 - mse: 143.6830 - val_loss: 7.6219 - val_mse: 105.2134\n",
      "Epoch 145/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.8104 - mse: 166.9958 - val_loss: 7.5912 - val_mse: 104.5411\n",
      "Epoch 146/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.3431 - mse: 146.7454 - val_loss: 7.5598 - val_mse: 103.8542\n",
      "Epoch 147/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2637 - mse: 143.9102 - val_loss: 7.5293 - val_mse: 103.1864\n",
      "Epoch 148/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 9.4512 - mse: 148.0562 - val_loss: 7.4987 - val_mse: 102.5072\n",
      "Epoch 149/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.0326 - mse: 135.1513 - val_loss: 7.4690 - val_mse: 101.8537\n",
      "Epoch 150/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.8857 - mse: 140.6365 - val_loss: 7.4425 - val_mse: 101.2876\n",
      "Epoch 151/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2792 - mse: 144.6093 - val_loss: 7.4108 - val_mse: 100.6026\n",
      "Epoch 152/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.2329 - mse: 109.2208 - val_loss: 7.3826 - val_mse: 100.0055\n",
      "Epoch 153/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3732 - mse: 114.3165 - val_loss: 7.3550 - val_mse: 99.4342\n",
      "Epoch 154/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4030 - mse: 119.7765 - val_loss: 7.3265 - val_mse: 98.8457\n",
      "Epoch 155/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.2371 - mse: 145.0167 - val_loss: 7.2966 - val_mse: 98.1876\n",
      "Epoch 156/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1803 - mse: 113.0132 - val_loss: 7.2729 - val_mse: 97.6975\n",
      "Epoch 157/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5539 - mse: 128.7535 - val_loss: 7.2467 - val_mse: 97.1324\n",
      "Epoch 158/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.3460 - mse: 112.7611 - val_loss: 7.2203 - val_mse: 96.5785\n",
      "Epoch 159/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7342 - mse: 132.5532 - val_loss: 7.1922 - val_mse: 95.9842\n",
      "Epoch 160/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.8004 - mse: 131.7394 - val_loss: 7.1658 - val_mse: 95.4453\n",
      "Epoch 161/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2563 - mse: 118.4444 - val_loss: 7.1387 - val_mse: 94.8911\n",
      "Epoch 162/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5904 - mse: 122.7804 - val_loss: 7.1116 - val_mse: 94.3420\n",
      "Epoch 163/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.9887 - mse: 137.8689 - val_loss: 7.0843 - val_mse: 93.7984\n",
      "Epoch 164/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7905 - mse: 125.4189 - val_loss: 7.0596 - val_mse: 93.3133\n",
      "Epoch 165/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9222 - mse: 110.0993 - val_loss: 7.0338 - val_mse: 92.7996\n",
      "Epoch 166/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5680 - mse: 126.1379 - val_loss: 7.0090 - val_mse: 92.2942\n",
      "Epoch 167/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.4892 - mse: 115.0616 - val_loss: 6.9846 - val_mse: 91.8116\n",
      "Epoch 168/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3205 - mse: 120.0495 - val_loss: 6.9583 - val_mse: 91.2825\n",
      "Epoch 169/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.4981 - mse: 116.3709 - val_loss: 6.9345 - val_mse: 90.8448\n",
      "Epoch 170/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2548 - mse: 122.1372 - val_loss: 6.9086 - val_mse: 90.3281\n",
      "Epoch 171/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5969 - mse: 100.9408 - val_loss: 6.8872 - val_mse: 89.9393\n",
      "Epoch 172/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0371 - mse: 112.5595 - val_loss: 6.8642 - val_mse: 89.4896\n",
      "Epoch 173/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.7989 - mse: 135.1540 - val_loss: 6.8432 - val_mse: 89.1064\n",
      "Epoch 174/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.7792 - mse: 131.5978 - val_loss: 6.8202 - val_mse: 88.6607\n",
      "Epoch 175/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8086 - mse: 104.5569 - val_loss: 6.7989 - val_mse: 88.2639\n",
      "Epoch 176/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2827 - mse: 113.9284 - val_loss: 6.7774 - val_mse: 87.8614\n",
      "Epoch 177/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1159 - mse: 110.7373 - val_loss: 6.7593 - val_mse: 87.5521\n",
      "Epoch 178/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8119 - mse: 111.6610 - val_loss: 6.7410 - val_mse: 87.2344\n",
      "Epoch 179/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.9536 - mse: 112.4198 - val_loss: 6.7204 - val_mse: 86.8646\n",
      "Epoch 180/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.5411 - mse: 127.7474 - val_loss: 6.7008 - val_mse: 86.5153\n",
      "Epoch 181/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.2614 - mse: 119.0999 - val_loss: 6.6824 - val_mse: 86.1947\n",
      "Epoch 182/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 8.4103 - mse: 123.4081 - val_loss: 6.6623 - val_mse: 85.8234\n",
      "Epoch 183/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 9.3749 - mse: 155.4648 - val_loss: 6.6439 - val_mse: 85.5110\n",
      "Epoch 184/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8586 - mse: 110.8243 - val_loss: 6.6256 - val_mse: 85.2044\n",
      "Epoch 185/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6975 - mse: 100.3697 - val_loss: 6.6075 - val_mse: 84.9067\n",
      "Epoch 186/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9980 - mse: 114.6308 - val_loss: 6.5863 - val_mse: 84.5134\n",
      "Epoch 187/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.7208 - mse: 106.7353 - val_loss: 6.5701 - val_mse: 84.2525\n",
      "Epoch 188/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1114 - mse: 114.4898 - val_loss: 6.5487 - val_mse: 83.8661\n",
      "Epoch 189/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2985 - mse: 126.1516 - val_loss: 6.5278 - val_mse: 83.4918\n",
      "Epoch 190/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0426 - mse: 113.1586 - val_loss: 6.5102 - val_mse: 83.1891\n",
      "Epoch 191/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 8.5242 - mse: 134.7733 - val_loss: 6.4913 - val_mse: 82.8698\n",
      "Epoch 192/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.0510 - mse: 120.5685 - val_loss: 6.4703 - val_mse: 82.5026\n",
      "Epoch 193/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5056 - mse: 101.9440 - val_loss: 6.4504 - val_mse: 82.1608\n",
      "Epoch 194/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3406 - mse: 124.7302 - val_loss: 6.4318 - val_mse: 81.8545\n",
      "Epoch 195/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3494 - mse: 100.3025 - val_loss: 6.4112 - val_mse: 81.5061\n",
      "Epoch 196/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2424 - mse: 118.5342 - val_loss: 6.3889 - val_mse: 81.1168\n",
      "Epoch 197/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4057 - mse: 99.7688 - val_loss: 6.3728 - val_mse: 80.8611\n",
      "Epoch 198/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3181 - mse: 119.6198 - val_loss: 6.3539 - val_mse: 80.5485\n",
      "Epoch 199/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8716 - mse: 116.4427 - val_loss: 6.3334 - val_mse: 80.2014\n",
      "Epoch 200/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.1533 - mse: 123.6017 - val_loss: 6.3157 - val_mse: 79.9015\n",
      "Epoch 201/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1091 - mse: 89.6029 - val_loss: 6.2984 - val_mse: 79.6018\n",
      "Epoch 202/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5682 - mse: 98.5436 - val_loss: 6.2784 - val_mse: 79.2458\n",
      "Epoch 203/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6405 - mse: 105.3509 - val_loss: 6.2617 - val_mse: 78.9692\n",
      "Epoch 204/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.8027 - mse: 112.8129 - val_loss: 6.2442 - val_mse: 78.6765\n",
      "Epoch 205/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.5419 - mse: 107.1083 - val_loss: 6.2269 - val_mse: 78.3866\n",
      "Epoch 206/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4572 - mse: 101.8860 - val_loss: 6.2092 - val_mse: 78.0872\n",
      "Epoch 207/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.3016 - mse: 122.4132 - val_loss: 6.1909 - val_mse: 77.7784\n",
      "Epoch 208/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9538 - mse: 110.7943 - val_loss: 6.1726 - val_mse: 77.4705\n",
      "Epoch 209/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0329 - mse: 86.1297 - val_loss: 6.1567 - val_mse: 77.2214\n",
      "Epoch 210/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2764 - mse: 94.1636 - val_loss: 6.1375 - val_mse: 76.9090\n",
      "Epoch 211/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.9324 - mse: 107.1247 - val_loss: 6.1191 - val_mse: 76.6024\n",
      "Epoch 212/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.5648 - mse: 103.0806 - val_loss: 6.1033 - val_mse: 76.3616\n",
      "Epoch 213/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3821 - mse: 95.1627 - val_loss: 6.0850 - val_mse: 76.0620\n",
      "Epoch 214/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3974 - mse: 93.3601 - val_loss: 6.0659 - val_mse: 75.7507\n",
      "Epoch 215/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9475 - mse: 88.5826 - val_loss: 6.0508 - val_mse: 75.5238\n",
      "Epoch 216/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1914 - mse: 97.9781 - val_loss: 6.0326 - val_mse: 75.2359\n",
      "Epoch 217/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5846 - mse: 106.0107 - val_loss: 6.0167 - val_mse: 74.9912\n",
      "Epoch 218/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4944 - mse: 98.1950 - val_loss: 5.9993 - val_mse: 74.7028\n",
      "Epoch 219/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3640 - mse: 93.0247 - val_loss: 5.9846 - val_mse: 74.4695\n",
      "Epoch 220/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1616 - mse: 94.1092 - val_loss: 5.9678 - val_mse: 74.1720\n",
      "Epoch 221/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 8.2201 - mse: 118.5473 - val_loss: 5.9543 - val_mse: 73.9670\n",
      "Epoch 222/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2340 - mse: 99.5017 - val_loss: 5.9387 - val_mse: 73.6977\n",
      "Epoch 223/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.8401 - mse: 113.2896 - val_loss: 5.9229 - val_mse: 73.4286\n",
      "Epoch 224/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9732 - mse: 84.4477 - val_loss: 5.9085 - val_mse: 73.2016\n",
      "Epoch 225/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2730 - mse: 94.1281 - val_loss: 5.8931 - val_mse: 72.9411\n",
      "Epoch 226/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.5002 - mse: 104.2425 - val_loss: 5.8775 - val_mse: 72.6832\n",
      "Epoch 227/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.0321 - mse: 90.9635 - val_loss: 5.8609 - val_mse: 72.3999\n",
      "Epoch 228/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.3136 - mse: 93.4653 - val_loss: 5.8473 - val_mse: 72.2122\n",
      "Epoch 229/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.2029 - mse: 92.2127 - val_loss: 5.8330 - val_mse: 71.9791\n",
      "Epoch 230/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.4803 - mse: 102.2644 - val_loss: 5.8187 - val_mse: 71.7316\n",
      "Epoch 231/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.2249 - mse: 96.6342 - val_loss: 5.8051 - val_mse: 71.4961\n",
      "Epoch 232/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.1275 - mse: 97.6026 - val_loss: 5.7929 - val_mse: 71.3076\n",
      "Epoch 233/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1003 - mse: 98.4086 - val_loss: 5.7796 - val_mse: 71.0852\n",
      "Epoch 234/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.1991 - mse: 95.3657 - val_loss: 5.7665 - val_mse: 70.8779\n",
      "Epoch 235/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6549 - mse: 100.7691 - val_loss: 5.7533 - val_mse: 70.6636\n",
      "Epoch 236/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5701 - mse: 73.3163 - val_loss: 5.7399 - val_mse: 70.4405\n",
      "Epoch 237/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8498 - mse: 83.4229 - val_loss: 5.7248 - val_mse: 70.1779\n",
      "Epoch 238/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.8240 - mse: 91.9790 - val_loss: 5.7104 - val_mse: 69.9318\n",
      "Epoch 239/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5817 - mse: 80.7246 - val_loss: 5.6965 - val_mse: 69.6944\n",
      "Epoch 240/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9441 - mse: 94.2696 - val_loss: 5.6825 - val_mse: 69.4257\n",
      "Epoch 241/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.9353 - mse: 87.2959 - val_loss: 5.6712 - val_mse: 69.2360\n",
      "Epoch 242/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8635 - mse: 87.5180 - val_loss: 5.6603 - val_mse: 69.0503\n",
      "Epoch 243/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2479 - mse: 100.5103 - val_loss: 5.6472 - val_mse: 68.8092\n",
      "Epoch 244/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.6629 - mse: 112.4839 - val_loss: 5.6346 - val_mse: 68.5808\n",
      "Epoch 245/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.1726 - mse: 72.8415 - val_loss: 5.6252 - val_mse: 68.4316\n",
      "Epoch 246/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.4598 - mse: 79.7338 - val_loss: 5.6141 - val_mse: 68.2452\n",
      "Epoch 247/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0506 - mse: 93.0081 - val_loss: 5.6024 - val_mse: 68.0355\n",
      "Epoch 248/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.0255 - mse: 90.9591 - val_loss: 5.5897 - val_mse: 67.8085\n",
      "Epoch 249/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.6518 - mse: 82.8683 - val_loss: 5.5774 - val_mse: 67.5914\n",
      "Epoch 250/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 6.5432 - mse: 83.3367 - val_loss: 5.5633 - val_mse: 67.3306\n",
      "Epoch 251/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.8296 - mse: 90.8328 - val_loss: 5.5537 - val_mse: 67.1918\n",
      "Epoch 252/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.0128 - mse: 68.3960 - val_loss: 5.5426 - val_mse: 67.0083\n",
      "Epoch 253/2000\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 6.7872 - mse: 85.8897 - val_loss: 5.5303 - val_mse: 66.7878\n",
      "Epoch 254/2000\n",
      "\u001b[1m22/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3811 - mse: 74.9736"
     ]
    }
   ],
   "source": [
    "historico = modelo.fit(X_train, y_train, epochs = 2000, batch_size=10, validation_split=0.2) # podemos poner verbose=0 para que no salga la barra de progreso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4dffc-9742-4da8-a984-4d10f706a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historico.history['mse'], c='b', label='Train')\n",
    "plt.plot(historico.history['val_mse'], c='g', label='Validation')\n",
    "plt.title('Training history')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011faf66-ef65-4542-a1e9-7f65886b6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones y calcular el error\n",
    "y_pred = modelo.predict(X_test)[:,0]  \n",
    "RMSE = np.sqrt(np.mean((y_test-y_pred)**2))\n",
    "np.round(RMSE, 3)\n",
    "print(f'Error (RMSE): {RMSE:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76963ba-c4f5-408a-b433-86d7bf699310",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = modelo.evalueate(X_test, y_test)\n",
    "print(MSE)\n",
    "print(np.sqrt(MSE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
